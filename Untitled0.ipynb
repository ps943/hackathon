{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ps943/hackathon/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jrb2eA1LhIOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "! pip install JIRA auto_ml Algorithmia gitpython"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wd066grRhUHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import doctest\n",
        "import requests\n",
        "import datetime\n",
        "from jira import JIRA\n",
        "from pymongo import MongoClient\n",
        "from auto_ml import Predictor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import pickle\n",
        "import Algorithmia\n",
        "from Algorithmia.errors import AlgorithmException\n",
        "import shutil\n",
        "import urllib.parse\n",
        "from git import Git, Repo, remote\n",
        "from IPython.display import YouTubeVideo\n",
        "from IPython.core.magic import register_line_cell_magic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tWPDD2kiE1a",
        "colab_type": "code",
        "outputId": "d99a51ca-40e7-481e-8120-868b4808f956",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "def raw_data():\n",
        "  x_train = np.linspace( -1 , 1 , 10000 )\n",
        "  y_train = 2 * x_train + np.random.randn( * x_train.shape)\n",
        "  df = pd.DataFrame(list(zip(x_train, y_train)),columns=[\"X\",\"Y\"])\n",
        "  return df\n",
        " \n",
        "df = raw_data()\n",
        "print(df)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           X         Y\n",
            "0    -1.0000 -2.777276\n",
            "1    -0.9998 -1.438186\n",
            "2    -0.9996 -2.240673\n",
            "3    -0.9994 -2.497843\n",
            "4    -0.9992 -1.875094\n",
            "...      ...       ...\n",
            "9995  0.9992  2.379166\n",
            "9996  0.9994  2.581196\n",
            "9997  0.9996  2.572523\n",
            "9998  0.9998  2.797895\n",
            "9999  1.0000  0.440545\n",
            "\n",
            "[10000 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piD6hM14Velp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G08QpIPX6Cai",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "603e2be9-e731-4b19-ec69-3c305434f8e4"
      },
      "source": [
        "def datastory(api_endpoint, input, header):\n",
        "    \"\"\"\n",
        "    Context:\n",
        "    This microservice is part of an AI that\n",
        "    automatically tells which area is most prone to crime\n",
        "\n",
        "    Intent:\n",
        "    The microservice predicts the number of crime type\n",
        "    in given area and on given date\n",
        "\n",
        "    Design:\n",
        "    >>> api_endpoint = \"https://api.algorithmia.com/v1/algo/nupur/dxchack/0.1.2?timeout=300\"\n",
        "    >>> input = '{\"X\": 0.9992}'\n",
        "    >>> header = {'Content-Type': 'application/json',  'Authorization': 'Simple simVPjkhYXvzsz5772zPyuTmU2V1'}\n",
        "    >>> datastory(api_endpoint, input, header)\n",
        "    2.0997937032487273\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "      headers = {\n",
        "          'Content-Type': 'application/json',\n",
        "          'Authorization': 'Simple simVPjkhYXvzsz5772zPyuTmU2V1',\n",
        "      }\n",
        "      params = (\n",
        "          ('timeout', '300'),\n",
        "      )\n",
        "      data = input\n",
        "      response = requests.post(api_endpoint, headers=headers, params=params, data=data)\n",
        "      result = response.json()['result']['results']\n",
        "    \n",
        "    except Exception as error:\n",
        "      result = {error}\n",
        "\n",
        "    return result\n",
        "\n",
        "doctest.testmod(verbose=False)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TestResults(failed=0, attempted=4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrD816FoOJL9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtmStuYyOp7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_layer = {\n",
        "    \"connection_string\": \"mongodb://puneetsihag:wNv3lX0ZbqaMvXbd@cluster0-shard-00-00-otinj.azure.mongodb.net:27017,cluster0-shard-00-01-otinj.azure.mongodb.net:27017,cluster0-shard-00-02-otinj.azure.mongodb.net:27017/test?ssl=true&replicaSet=Cluster0-shard-0&authSource=admin&retryWrites=true&w=majority\",\n",
        "    \"collection_name\": \"Crime\",\n",
        "    \"database_name\": \"CrimeDatabase\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jSUNgPGOuXO",
        "colab_type": "code",
        "outputId": "35607670-4fc4-479f-d05e-8576c532572d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#connect to the data layer\n",
        "client = MongoClient(data_layer[\"connection_string\"])\n",
        "\n",
        "#start a data collection, build a database, insert the raw data\n",
        "db = client[data_layer[\"database_name\"]][data_layer[\"collection_name\"]]\n",
        "db.insert_many(raw_data().to_dict('records'))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pymongo.results.InsertManyResult at 0x7f8578b3d148>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qx8irKTVgC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class model:\n",
        "  __model = []\n",
        "  def build(self, meta_data): raise NotImplementedError()\n",
        "  def train_and_score(self, data): raise NotImplementedError()\n",
        "  def interpret(self): raise NotImplementedError()\n",
        "  def python_object(): raise NotImplementedError()\n",
        "\n",
        "  @staticmethod\n",
        "  def meta_data_key(meta_data, value):\n",
        "    key_list = list(meta_data.keys()) \n",
        "    val_list = list(meta_data.values()) \n",
        "  \n",
        "    return key_list[val_list.index(value)] \n",
        "\n",
        "#define the model lifecycle\n",
        "def run_experiment(design):\n",
        "  design[\"model\"].build(design[\"meta_data\"])\n",
        "  design[\"model\"].train_and_score(design[\"data\"], design[\"labels\"])\n",
        "  design[\"model\"].interpret()\n",
        "  return design[\"model\"].python_object()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OjeMot6Vjit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class prediction(model):\n",
        "  def build(self, meta_data):\n",
        "    self.__model = Predictor(type_of_estimator='regressor', column_descriptions=meta_data)\n",
        "    self.__label = self.meta_data_key(meta_data, \"output\")\n",
        "\n",
        "  def train_and_score(self, data, labels):\n",
        "    # create training and test data\n",
        "    training_data, test_data = train_test_split(data, test_size=0.2)\n",
        "\n",
        "    # train the model\n",
        "    self.__model.train(training_data, verbose=False, ml_for_analytics=False)\n",
        "  \n",
        "    # score the model\n",
        "    self.__model.score(test_data, test_data[self.__label], verbose=0)\n",
        "  \n",
        "  def interpret(self):\n",
        "    pass\n",
        "  \n",
        "  def python_object(self):\n",
        "    return self.__model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWBNpvYKVmdi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "75781480-3d30-4e0d-d99d-6009d6cbad01"
      },
      "source": [
        "experiment_design = {\n",
        "    \"model\": prediction(),\n",
        "    \"labels\": df.X,\n",
        "    \"data\": df,\n",
        "    \"meta_data\": {\n",
        "      \"Y\": \"output\",\n",
        "  }\n",
        "}\n",
        "trained_model = run_experiment(experiment_design)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now using the model training_params that you passed in:\n",
            "{}\n",
            "After overwriting our defaults with your values, here are the final params that will be used to initialize the model:\n",
            "{'presort': False, 'learning_rate': 0.1, 'warm_start': True}\n",
            "Running basic data cleaning\n",
            "Fitting DataFrameVectorizer\n",
            "Now using the model training_params that you passed in:\n",
            "{}\n",
            "After overwriting our defaults with your values, here are the final params that will be used to initialize the model:\n",
            "{'presort': False, 'learning_rate': 0.1, 'warm_start': True}\n",
            "\n",
            "\n",
            "********************************************************************************************\n",
            "About to fit the pipeline for the model GradientBoostingRegressor to predict Y\n",
            "Started at:\n",
            "2019-12-03 15:26:52\n",
            "[1] random_holdout_set_from_training_data's score is: -1.488\n",
            "[2] random_holdout_set_from_training_data's score is: -1.415\n",
            "[3] random_holdout_set_from_training_data's score is: -1.352\n",
            "[4] random_holdout_set_from_training_data's score is: -1.299\n",
            "[5] random_holdout_set_from_training_data's score is: -1.255\n",
            "[6] random_holdout_set_from_training_data's score is: -1.217\n",
            "[7] random_holdout_set_from_training_data's score is: -1.185\n",
            "[8] random_holdout_set_from_training_data's score is: -1.159\n",
            "[9] random_holdout_set_from_training_data's score is: -1.137\n",
            "[10] random_holdout_set_from_training_data's score is: -1.118\n",
            "[11] random_holdout_set_from_training_data's score is: -1.103\n",
            "[12] random_holdout_set_from_training_data's score is: -1.09\n",
            "[13] random_holdout_set_from_training_data's score is: -1.079\n",
            "[14] random_holdout_set_from_training_data's score is: -1.071\n",
            "[15] random_holdout_set_from_training_data's score is: -1.064\n",
            "[16] random_holdout_set_from_training_data's score is: -1.058\n",
            "[17] random_holdout_set_from_training_data's score is: -1.053\n",
            "[18] random_holdout_set_from_training_data's score is: -1.049\n",
            "[19] random_holdout_set_from_training_data's score is: -1.046\n",
            "[20] random_holdout_set_from_training_data's score is: -1.043\n",
            "[21] random_holdout_set_from_training_data's score is: -1.041\n",
            "[22] random_holdout_set_from_training_data's score is: -1.039\n",
            "[23] random_holdout_set_from_training_data's score is: -1.038\n",
            "[24] random_holdout_set_from_training_data's score is: -1.036\n",
            "[25] random_holdout_set_from_training_data's score is: -1.035\n",
            "[26] random_holdout_set_from_training_data's score is: -1.034\n",
            "[27] random_holdout_set_from_training_data's score is: -1.033\n",
            "[28] random_holdout_set_from_training_data's score is: -1.032\n",
            "[29] random_holdout_set_from_training_data's score is: -1.032\n",
            "[30] random_holdout_set_from_training_data's score is: -1.031\n",
            "[31] random_holdout_set_from_training_data's score is: -1.031\n",
            "[32] random_holdout_set_from_training_data's score is: -1.03\n",
            "[33] random_holdout_set_from_training_data's score is: -1.03\n",
            "[34] random_holdout_set_from_training_data's score is: -1.03\n",
            "[35] random_holdout_set_from_training_data's score is: -1.03\n",
            "[36] random_holdout_set_from_training_data's score is: -1.03\n",
            "[37] random_holdout_set_from_training_data's score is: -1.03\n",
            "[38] random_holdout_set_from_training_data's score is: -1.03\n",
            "[39] random_holdout_set_from_training_data's score is: -1.03\n",
            "[40] random_holdout_set_from_training_data's score is: -1.031\n",
            "[41] random_holdout_set_from_training_data's score is: -1.031\n",
            "[42] random_holdout_set_from_training_data's score is: -1.031\n",
            "[43] random_holdout_set_from_training_data's score is: -1.031\n",
            "[44] random_holdout_set_from_training_data's score is: -1.031\n",
            "[45] random_holdout_set_from_training_data's score is: -1.031\n",
            "[46] random_holdout_set_from_training_data's score is: -1.031\n",
            "[47] random_holdout_set_from_training_data's score is: -1.03\n",
            "[48] random_holdout_set_from_training_data's score is: -1.031\n",
            "[49] random_holdout_set_from_training_data's score is: -1.03\n",
            "[50] random_holdout_set_from_training_data's score is: -1.03\n",
            "[52] random_holdout_set_from_training_data's score is: -1.031\n",
            "[54] random_holdout_set_from_training_data's score is: -1.031\n",
            "[56] random_holdout_set_from_training_data's score is: -1.031\n",
            "[58] random_holdout_set_from_training_data's score is: -1.032\n",
            "The number of estimators that were the best for this training dataset: 34\n",
            "The best score on the holdout set: -1.029974345602882\n",
            "Finished training the pipeline!\n",
            "Total training time:\n",
            "0:00:01\n",
            "Calculating feature responses, for advanced analytics.\n",
            "Here are our feature responses for the trained model\n",
            "+----+----------------+---------+-------------------+-------------------+-----------+-----------+\n",
            "|    | Feature Name   |   Delta |   FR_Decrementing |   FR_Incrementing |   FRD_MAD |   FRI_MAD |\n",
            "|----+----------------+---------+-------------------+-------------------+-----------+-----------|\n",
            "|  0 | X              |  0.2896 |           -0.5308 |            0.5159 |    0.5490 |    0.5430 |\n",
            "+----+----------------+---------+-------------------+-------------------+-----------+-----------+\n",
            "None\n",
            "\n",
            "\n",
            "***********************************************\n",
            "Advanced scoring metrics for the trained regression model on this particular dataset:\n",
            "\n",
            "Here is the overall RMSE for these predictions:\n",
            "0.9902582043967049\n",
            "\n",
            "Here is the average of the predictions:\n",
            "-0.0019813179255547793\n",
            "\n",
            "Here is the average actual value on this validation set:\n",
            "-0.028536885173982535\n",
            "\n",
            "Here is the median prediction:\n",
            "-0.08756977524960026\n",
            "\n",
            "Here is the median actual value:\n",
            "-0.022805137762463554\n",
            "\n",
            "Here is the mean absolute error:\n",
            "0.7908293487450432\n",
            "\n",
            "Here is the median absolute error (robust to outliers):\n",
            "0.6657180276338341\n",
            "\n",
            "Here is the explained variance:\n",
            "0.5688666644723119\n",
            "\n",
            "Here is the R-squared value:\n",
            "0.5685563955319228\n",
            "Count of positive differences (prediction > actual):\n",
            "1048\n",
            "Count of negative differences:\n",
            "952\n",
            "Average positive difference:\n",
            "0.7799474389250678\n",
            "Average negative difference:\n",
            "-0.8028085940090501\n",
            "\n",
            "\n",
            "***********************************************\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuzNeNvWWB1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO design a microservice\n",
        "microservice_design = {\n",
        "    \"microservice_name\": \"dxchack\",\n",
        "    \"microservice_description\": \"test api generated from the DXC ai starter\",\n",
        "    \"execution_environment_username\": \"nupur\",\n",
        "    \"api_key\": \"simVPjkhYXvzsz5772zPyuTmU2V1\",\n",
        "    \"api_namespace\": \"nupur/dxchack\",\n",
        "    \"model_path\":\"data://.my/mycollection\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbivvdFnWfPc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "e2d92328-68f3-40ef-c86c-288d3c3f8c72"
      },
      "source": [
        "# create a connection to algorithmia\n",
        "client=Algorithmia.client(microservice_design[\"api_key\"])\n",
        "api = client.algo(microservice_design[\"execution_environment_username\"] + \"/\" + microservice_design[\"microservice_name\"])\n",
        "\n",
        "# create the api if it doesn't exist\n",
        "try:\n",
        "  api.create(\n",
        "    details = {\n",
        "        \"label\": api_label(),\n",
        "    },\n",
        "    settings = {\n",
        "        \"language\": \"python3-1\",\n",
        "        \"source_visibility\": \"closed\",\n",
        "        \"license\": \"apl\",\n",
        "        \"network_access\": \"full\",\n",
        "        \"pipeline_enabled\": True,\n",
        "        \"environment\": \"cpu\"\n",
        "    }\n",
        ")\n",
        "except Exception as error:\n",
        "    print(error)\n",
        "\n",
        "# create data collection if it doesn't exist\n",
        "if not client.dir(microservice_design[\"model_path\"]).exists():\n",
        "    client.dir(microservice_design[\"model_path\"]).create()\n",
        "\n",
        "# define a local work directory\n",
        "local_dir = microservice_design[\"microservice_name\"]\n",
        "\n",
        "# delete local directory if it already exists\n",
        "if os.path.exists(local_dir):\n",
        "    shutil.rmtree(local_dir)\n",
        "\n",
        "# create local work directory\n",
        "os.makedirs(local_dir)\n",
        "\n",
        "# serialize the model locally\n",
        "local_model = \"{}/{}\".format(local_dir, \"mdl\")\n",
        "\n",
        "# open a file in a specified location\n",
        "file = open(local_model, 'wb')\n",
        "# dump information to that file\n",
        "pickle.dump(trained_model, file)\n",
        "# close the file\n",
        "file.close()\n",
        "\n",
        "# upload our model file to our data collection\n",
        "api_model = \"{}/{}\".format(microservice_design[\"model_path\"], microservice_design[\"microservice_name\"])\n",
        "client.file(api_model).putFile(local_model)\n",
        "\n",
        "# encode API key, so we can use it in the git URL\n",
        "encoded_api_key = urllib.parse.quote_plus(microservice_design[\"api_key\"])\n",
        "\n",
        "algo_repo = \"https://{}:{}@git.algorithmia.com/git/{}/{}.git\".format(\n",
        "    microservice_design[\"execution_environment_username\"], \n",
        "    encoded_api_key, \n",
        "    microservice_design[\"execution_environment_username\"], \n",
        "    microservice_design[\"microservice_name\"]\n",
        "    )\n",
        "\n",
        "class Progress(remote.RemoteProgress):\n",
        "    def line_dropped(self, line):\n",
        "        print(line)\n",
        "    def update(self, *args):\n",
        "        print(self._cur_line)\n",
        "\n",
        "p = Progress()\n",
        "\n",
        "try:\n",
        "  Repo.clone_from(algo_repo, \"{}/{}\".format(local_dir, microservice_design[\"microservice_name\"]), progress=p)\n",
        "  cloned_repo = Repo(\"{}/{}\".format(local_dir, microservice_design[\"microservice_name\"]))\n",
        "except Exception as error:\n",
        "  print(\"here\")\n",
        "  print(error)\n",
        "\n",
        "api_script_path = \"{}/{}/src/{}.py\".format(local_dir, microservice_design[\"microservice_name\"], microservice_design[\"microservice_name\"])\n",
        "dependency_file_path = \"{}/{}/{}\".format(local_dir, microservice_design[\"microservice_name\"], \"requirements.txt\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name 'api_label' is not defined\n",
            "Cloning into 'dxchack/dxchack'...\n",
            "POST git-upload-pack (141 bytes)\n",
            "remote: Counting objects: 1\n",
            "remote: Counting objects: 13, done\n",
            "remote: Finding sources:   7% (1/13)\n",
            "remote: Finding sources:  15% (2/13)\n",
            "remote: Finding sources:  23% (3/13)\n",
            "remote: Finding sources:  30% (4/13)\n",
            "remote: Finding sources:  38% (5/13)\n",
            "remote: Finding sources:  46% (6/13)\n",
            "remote: Finding sources:  53% (7/13)\n",
            "remote: Finding sources:  61% (8/13)\n",
            "remote: Finding sources:  69% (9/13)\n",
            "remote: Finding sources:  76% (10/13)\n",
            "remote: Finding sources:  84% (11/13)\n",
            "remote: Finding sources:  92% (12/13)\n",
            "remote: Finding sources: 100% (13/13)\n",
            "remote: Finding sources: 100% (13/13)\n",
            "remote: Getting sizes:   9% (1/11)\n",
            "remote: Getting sizes:  18% (2/11)\n",
            "remote: Getting sizes:  27% (3/11)\n",
            "remote: Getting sizes:  36% (4/11)\n",
            "remote: Getting sizes:  45% (5/11)\n",
            "remote: Getting sizes:  54% (6/11)\n",
            "remote: Getting sizes:  63% (7/11)\n",
            "remote: Getting sizes:  72% (8/11)\n",
            "remote: Getting sizes:  81% (9/11)\n",
            "remote: Getting sizes:  90% (10/11)\n",
            "remote: Getting sizes: 100% (11/11)\n",
            "remote: Getting sizes: 100% (11/11)\n",
            "remote: Total 13 (delta 0), reused 13 (delta 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MkRwwtqWsKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iW2TVNuWvVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = \"{'results':prediction}\"\n",
        "file_path = \"'\" + api_model + \"'\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuZOVWKfWyao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writetemplate $api_script_path\n",
        "import Algorithmia\n",
        "import auto_ml\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "# create an Algorithmia client\n",
        "client = Algorithmia.client()\n",
        "\n",
        "def load_model():\n",
        "    # Get file by name\n",
        "    # Open file and load model\n",
        "    file_path = {file_path}\n",
        "    model_path = client.file(file_path).getFile().name\n",
        "    # Open file and load model\n",
        "    with open(model_path, 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "        return model\n",
        "\n",
        "trained_model = load_model()\n",
        "\n",
        "def apply(input):\n",
        "    \n",
        "    \n",
        "    prediction = trained_model.predict(input)\n",
        "    return {results}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2hyj6T9W1gV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f322f845-0e83-4e66-d9c0-a90bad52e8e3"
      },
      "source": [
        "%%writefile $dependency_file_path\n",
        "algorithmia>=1.0.0,<2.0\n",
        "six\n",
        "auto_ml\n",
        "pandas\n",
        "bottleneck==1.2.1"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting dxchack/dxchack/requirements.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9nHU4wuW5Ey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "0ab88eb0-e95d-4135-f4ad-a64a0fa63316"
      },
      "source": [
        "files = [\"src/{}.py\".format(microservice_design[\"microservice_name\"]), \"requirements.txt\"]\n",
        "cloned_repo.index.add(files)\n",
        "cloned_repo.index.commit(\"Add algorithm files\")\n",
        "origin = cloned_repo.remote(name='origin')\n",
        "\n",
        "class Progress(remote.RemoteProgress):\n",
        "    def line_dropped(self, line):\n",
        "        print(line)\n",
        "    def update(self, *args):\n",
        "        print(self._cur_line)\n",
        "\n",
        "p = Progress()\n",
        "\n",
        "origin.push(progress=p)\n",
        "\n",
        "# publish/deploy our algorithm\n",
        "client.algo(microservice_design[\"api_namespace\"]).publish()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counting objects: 1, done.\n",
            "Writing objects: 100% (1/1)\n",
            "Writing objects: 100% (1/1), 180 bytes | 180.00 KiB/s, done.\n",
            "Total 1 (delta 0), reused 0 (delta 0)\n",
            "remote: Updating references: 100% (1/1)\n",
            "remote: Updating references: 100% (1/1)\n",
            "remote:\n",
            "remote: Build successful for algo://nupur/dxchack/1faff11db7a9cf7a9d7e04f6bae8a89560c85d96\n",
            "remote:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'build': None,\n",
              " 'compilation': {'output': None, 'successful': True},\n",
              " 'details': {'label': 'dxchack', 'summary': None, 'tagline': ''},\n",
              " 'name': 'dxchack',\n",
              " 'resource_type': 'algorithm',\n",
              " 'self_link': None,\n",
              " 'settings': {'algorithm_callability': 'private',\n",
              "              'environment': 'cpu',\n",
              "              'language': 'python3-1',\n",
              "              'license': 'apl',\n",
              "              'network_access': 'full',\n",
              "              'package_set': None,\n",
              "              'pipeline_enabled': True,\n",
              "              'royalty_microcredits': None,\n",
              "              'source_visibility': 'open'},\n",
              " 'version_info': {'git_hash': '1faff11db7a9cf7a9d7e04f6bae8a89560c85d96',\n",
              "                  'release_notes': None,\n",
              "                  'sample_input': None,\n",
              "                  'sample_output': None,\n",
              "                  'semantic_version': '0.1.2'}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PshZXzsaXEhx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0441bf1-6a63-4a83-d010-0cb180e24a09"
      },
      "source": [
        "# display the url to the api\n",
        "latest_version = client.algo(microservice_design[\"api_namespace\"]).info().version_info.semantic_version\n",
        "api_url = \"https://api.algorithmia.com/v1/algo/{}/{}\".format(microservice_design[\"api_namespace\"], latest_version)\n",
        "print(\"api url: \" + api_url)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "api url: https://api.algorithmia.com/v1/algo/nupur/dxchack/0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}